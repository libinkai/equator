# 数据同步

- 数据同步指的是同类型不同集群（节点）系统的数据传输，如主数据库到从数据库的数据同步备份；或者是不同地域，不同类型系统间的数据传输，如实时消息队列到数据仓库的传输（Kafka to Hive）。

## 数据同步基础

### 直连同步

- 通过规范接口API（如JDBC）和动态链接库的方式，从源系统到目标系统直接建立连接进行数据传输。
- 此方法对源数据库影响较大，性能不高，不适合从业务数据库同步数据到数据仓库等场景。

### 数据文件同步

- 通过固定的文件编码，从源数据生成数据的文本文件后，由专门的文件服务器将数据文件从源系统传输到目标系统。
- 传输过程中可以进行数据的压缩以减小数据的大小。由于可以生成统一的数据文件，比较适合源系统包含多个异构数据库系统的场景。

### 数据库日志解析同步

- 通过源系统的进程读取解析日志文件收集数据变化情况，解析到目标数据文件中，并通过网络传输将数据文件同步到目标系统。目标系统通过数据加载模块完成数据的导入实现从源系统到目标系统的数据同步。
- 此方法对源系统影响较小，实现了（准）实时的数据同步能力，广泛应用于业务系统同步数据到数据仓库的场景。

## 数据仓库的同步方式

- 数据仓库的数据同步特点之一是数据来源丰富，不仅有结构化的数据库数据，还有非结构化的日志、多媒体等数据。特点之二是数据量大，每天处理数据规模超EB级别。

### 批量数据同步

- 利用`DataX`作为异构数据交换服务，从数据源读取数据转换为中间状态，传输到目标数据系统后转换为对应的数据格式。

### 实时数据同步

- 通过读取业务系统的日志数据或者解析业务数据库系统中的`binlog`或归档日志，增量同步到日志交换中心（`TimeTunnel`），下游系统通过消息订阅模式获取最新的实时数据。

## 数据同步的挑战

### 分库分表

- 为了应对巨大的数据量，很多数据库系统都采用了分库分表的方案，但是分散的数据也给数据同步带来了挑战。
- 阿里巴巴采用`TDDL`（Taobao Distributed Data Layer）这个分布式数据库访问引擎，将分库分表后的库表合并为一个逻辑表，解决了分库分表的规则引擎问题。

### 高效同步与批量同步

- 数据同步的一般步骤是先创建目标表，再通过同步工具填写数据库连接、库表元数据的信息，测试数据同步流程。
- 阿里巴巴采用`OneClick`产品简化了以上流程，通过Web系统以及接口的方式对外提供可视化的，批量的数据同步配置操作。

### 增量同步与全量同步

- 在大数据量场景下，每次全量数据同步是不现实的，可以选择增量同步。而由于大部分大数据平台都不支持update操作，所以更常用的方式是使用全外连接（full outer join）+数据全量覆盖（insert overwrite）：使用全外连接将增量数据与存量数据合并为最新的全量数据，再将最新的全量数据覆盖旧的全量数据。

### 同步的性能

- 数据同步任务是数据同步工作的实际执行者，CPU分配不合理会导致数据同步任务运行不稳定。
- 阿里巴巴的解决方案是评估目标数据集的规模估算需要的线程数，同时给任务标定优先级，提高数据同步任务的执行效率与稳定性。

### 漂移数据的处理

- 数据库仓库的数据都是分层的，第一层为ODS（或者叫staging层）。数据漂移指的是ODS数据表中一个日期的数据中包含了前一天或者后一天时间临界点前后的数据。
- 数据仓库ODS表需要按照时间段进行分区存储，一般做法是按照某个时间戳来进行分区。主要的时间戳有数据库中标记数据更新时间、日志中标记数据更新的时间、数据库中标记业务过程发生的时间（如订单业务，包含下单、支付、支付成功等过程，有多个时间戳）、数据被抽取到数据仓库的时间。按照不同的时间戳进行分区，其数据漂移现象也不尽相同。

- 解决数据漂移的常规方法是先获取临界点前后一段时间（如15min）的数据，再按照时间戳进行筛选后回填到当天的数据中。