# 计算管理

> 如何降低计算资源的消耗，提高任务执行的性能，提升任务产出的效率是计算平台与ETL工程师孜孜以求的目标。

## 系统优化

- Hadoop等计算系统主要通过输入数据规模进行资源的评估，对于Map任务评估结果较为准确，但是Reduce任务的输入是Map任务的输出，其规模是不确定的。可以通过HBO（History Based Optimizer，基于历史的优化器）解决这个问题，即在任务运行稳定的情况下，根据任务实际情况调整资源配置。
- CBO（Cost Based Optimizer，基于代价的优化器），指的是使用抽样统计算法，以较小的资源获取大量的统计信息，用于生成更优的执行计划。

### HBO

- 任务执行历史+集群状态信息+优化规则=更优的执行配置

- HBO前提是最近七天任务代码没有发生变化且任务运行4次，Instance分配逻辑是为基础资源估算值+加权资源估算值
  - 基础资源估算值：根据每个Map Task的处理能力结合用户输入数据规模评估所需Map Task数量。使用最近7天Reduce对应Map的平均输出量作为Reduce的输入数据量进行资源估算。
  - 加权资源估算值：计算Map Task最近一段时间内平均处理速度与系统设定的期望处理速度对比，如果平均处理速度小于预期值，则按照比例增加资源。Reduce Task任务同理。

### CBO

- CBO由多个模块相互协调工作
  - Meta Manager，提供元数据信息如表的元数据，如分区信息。
  - Statistics，提供准确的统计信息，如表的数量，列的枚举值等。
  - Rule Set，优化规则，根据不同情况选择不同的优化点。
  - Volcano Planner Core，将以上信息综合起来通过代价模型的计算得出一个最优的执行计划。

## 任务优化

> SQL/MR作业一般生成MapReduce任务，任务优化指的是解决MapReduce过程中数据倾斜的问题。

### Map倾斜

- 引起倾斜的原因
  - 上游表文件大小不均匀且小文件较多，会导致当前表的Map Task读取的数据分布不均匀
  - Map端做聚合操作时，由于某些Map端读取文件的某个值特别多（主要指的是Count Distinct操作）

- 解决方案
  - 针对原因1，可以通过对上游合并小文件，同时调整本节点的小文件参数，防止小文件过多导致Map端读取数据过多。
  - 针对原因2，可以通过`distribute by rand()`语法将Map端分发后的数据重新按照随机值分发，Map端只负责数据的分发，不进行复杂的聚合或者笛卡尔积操作。

### Join倾斜

- 引起倾斜的原因
  - Join的某路输入比较小
  - Join的每路输入都比较大，且由于空值导致长尾
  - Join的每路输入都比较大，且由于热点值导致长尾
- 解决方案
  - 针对原因1，通过MapJoin将Join操作提前到Map端完成，将小表读入内存，扫描大表完成Join。
  - 针对原因2，将空值填充为随机值，避免空值的聚集导致长尾。
  - 针对原因3，将热点key取出，对主表数据进行热点与非热点的切分，分别进行处理后合并。

### Reduce倾斜

- 引起倾斜的原因
  - 对同一个表按照维度对不同的列进行Count Distinct操作，造成Map端数据膨胀，使得下游Join与Reduce环节出现链路上的长尾
  - Map端直接聚合时由于key分布不均匀导致Reduce端长尾
  - 动态分区数过多导致小文件过多
  - 多个Distinct同时出现在一段SQL中，数据被分发多次
- 解决方案
  - 针对原因2，对热点key与非热点key进行切分后单独处理，与解决Join倾斜的原理一致。
  - 针对原因3，把符合不同条件的数据放到不同的分区，避免通过多次“Insert Overwrite”写入表中。
  - 针对原因1和4，可以先分别进行查询，再Group By，再Join。（看不球懂QAQ）

# 后话

- 本章还是非常难且晦涩的，后续实践环节再回头细品吧~

![image-20210807151552244](image-20210807151552244.png)