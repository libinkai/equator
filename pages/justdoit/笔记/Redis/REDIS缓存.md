# 缓存中间件

## MEMCACHE

- 支持简单数据类型
- 不支持数据持久化储存
- 不支持主从
- 不支持分片

## REDIS

- 数据格式丰富
- 支持数据磁盘持久化储存
- 支持主从
- 支持分片
- 10W+QPS（query per second）
- **单线程**，意思是单个主线程，但是有些工作会开启新的线程
- 使用多路IO复用模型，非阻塞IO

# IO多路复用

- FD（File Descriptor）文件描述符，一个打开的文件通过唯一的描述符进行引用，该描述符是打开文件的元数据到文件本身的映射，用一个整数来表示
- Select系统调用，监听可读文件描述符的个数并返回，O(n)保底方案
- `Epoll`
- `Kqueue`
- `Evport`

- 基于React设计模式监听IO事件，文件事件处理器

#数据结构

## STRING

- 二进制安全，可以包含任意类型的数据，最大512M
- 操作是原子性的
- Redis 没有直接使用C语言传统的字符串表示，而是自己构建了一种名为简单动态字符串（simple dynamic string SDS）的抽象类型，并将SDS用作Redis 的默认字符串表示;除了用来保存字符串以外，SDS还被用作缓冲区（buffer）AOF(持久化模块中的AOF缓冲区）
- 获取字符串长度（**SDS O（1）/C 字符串 O(n)**）
  **传统的C字符串**: 使用长度为N+1 的字符串数组来表示长度为N 的字符串，所以为了获取一个长度为C字符串的长度，必须遍历整个字符串。**SDS**：SDS 的数据结构中，有专门用于保存字符串长度的变量，我们可以通过获取len 属性的值，直接知道字符串长度
- C 字符串 不记录字符串长度，除了获取的时候复杂度高以外，还容易忘了为字符串重新分配足够的空间，从而导致缓冲区溢出。Redis 中SDS 的空间分配策略完全杜绝了发生缓冲区溢出的可能性：当我们需要对一个SDS进行修改的时候，redis会在执行拼接操作之前，预先检查给定SDS空间是否足够，如果不够，会先拓展SDS 的空间，然后再执行拼接操作
- **SDS**：对SDS进行拓展，则需要进行空间的拓展，这时候redis 会将SDS的长度修改为N字节，并且将未使用空间同样修改为N字节，此时如果再次进行修改，因为在上一次修改字符串的时候已经拓展了空间，再次进行修改字符串的时候如果发现空间足够使用，因此无须进行空间拓展。**通过这种预分配策略，SDS将连续增长N次字符串所需的内存重分配次数从必定N次降低为最多N次**

## HASH

- 特别适合储存一个对象
- 渐进式 rehash，采用渐进式rehash 的好处在于它采取分而治之的方式，避免了集中式rehash 带来的庞大计算量

## LIST

- 双端队列
- 按照String元素插入顺序排序
- 特点
  - 双端：链表节点带有prev 和next 指针，获取某个节点的前置节点和后置节点的时间复杂度都是O（N）
  - 无环：表头节点的 prev 指针和表尾节点的next 都指向NULL，对立案表的访问时以NULL为截止
  - 表头和表尾：因为链表带有head指针和tail 指针，程序获取链表头结点和尾节点的时间复杂度为O(1)
  - 长度计数器：链表中存有记录链表长度的属性 len
  - 多态：链表节点使用 void* 指针来保存节点值，并且可以通过list 结构的dup 、 free、 match三个属性为节点值设置类型特定函数

## SET

- 通过HASH实现
- 元素不允许重复
- 无序
- 可以方便地求交并补操作

## ZSET

- 有序集合，double类型的score作为排序标准，越小越前
- Redis 只在两个地方用到了跳跃表，一个是**实现有序集合键**，另外一个是**在集群节点中用作内部数据结构**

## HyperLogLog

- 用于计算基数

## Geo

- 地理位置信息

## 底层实现

- 简单动态字符串
- 链表
- 字典
- 跳跃表
- 整数集合
- 压缩列表
- 对象

# 内存淘汰

- 当超过最大内存 `maxmemory`时，redis将按照以下策略淘汰数据

## 淘汰机制

> redis确定驱逐某个键值对后，会删除这个数据，并将这个数据变更消息发布到本地（AOF 持久化）和从机（主从连接）

- `volatile-lru`：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰

- `volatile-ttl`：从已设置过期时间的数据集中挑选将要过期的数据淘汰

- `volatile-random`：从已设置过期时间的数据集中任意选择数据淘汰

- `allkeys-lru`：从数据集中挑选最近最少使用的数据淘汰

- `allkeys-random`：从数据集中任意选择数据淘汰

- `no-enviction`：禁止驱逐数据（默认）

# 场景

## 海量数据查询某一固定前缀Key

> 海量数据下使用keys关键字会造成服务器卡断

- 使用`SCAN cursor [match pattern] [count num]`，局部查询，会返回游标以及数据，将游标传入可继续查询，一轮一轮地获取
- 基于游标的迭代器，需要基于上一次的游标延续之前的迭代过程
- 以0作为游标开始一次新的迭代，直到命令返回游标0则完成一次遍历
- 不保证每次执行都会返回指定数量的元素，支持模糊查询
- 一次返回的数量不可控，只能是大概率符合count参数

## 实现分布式锁

- 分布式锁需要解决的问题
  - 互斥性
  - 安全性，解锁必须上锁人
  - 死锁
  - 容错

### 初期使用SETNX

- `SETNX key value`，如果key不存在，则创建并赋值，如果存在则不进行操作
- `EXPIRE key seconds`，设置有效期，解决SETNX长期有效的问题
- 缺点：不满足原子性，单个命令满足原子性，其组合不一定满足

### 改进

- `set key value [EX seconds] [PX milliseconds] [NX|XX]`
- EX秒，PX毫秒；
- NX只有在键值不存在的时候才对键进行操作，等效于SETNX；XX只在键值存在时，才对键进行操作
- 成功返回“OK”，失败返回“nil”

## 大量key同时过期（雪崩）

- 集中过期会造成短暂的卡顿现象
- 解决方法是在设置key过期时间时，加上随机值

## 实现异步队列

### 使用LIST

- 使用List作为队列，RPUSH生产队列，LPOP消费消息

- 缺点：没有等待队列就直接消费
- 弥补：应用层使用Sleep机制调用LPOP重试

### 使用BLPOP

- `BLPOP key [key...] timeout`，阻塞直到队列有消息或者超时

### PUB/SUB主题订阅者模式

> 一次生产，多次消费

- 发送者（pub）发送消息，订阅者（sub）接受消息
- 订阅者可以订阅任意数量的频道
- `subscribe topic`
- `publish topic content`
- 缺点：无状态，不保证可达

# 持久化

## RDB

> 快照，保存某个时间点的全量数据快照

```
save seconds write_times
// seconds内写请求达到write_times时进行持久化

stop-write-on-bgsave-error //备份出错时停止写入数据
rdbcompression // 压缩RDB备份文件
save "" 空串，禁用RDB配置
```

- 手动备份
  - SAVE，阻塞服务器进程进行备份
  - BGSAVE，Fork一个子进程来创建RDB文件，非阻塞
  - `lastsave`上一次备份时间
- 主动触发RDB持久化的方法
  - 配置文件里面的`save m n`定时触发（使用的是BGSAVE）
  - 主从复制时，主节点主动触发
  - 执行Debug Reload
  - 执行Shutdown而且没有开启AOF持久化的时候
- BGSAVE实现
  1. 检查是否没有其它RDB/AOF子进程
  2. 执行`rdbSaveBackground`方法
  3. Fork（Linux系统调用，创建进程，实现了copy on write 即写时复制：多个调用者共享资源，只有在写的时候才去拷贝一份资源）
- 由于COW机制，父子进程共享一个rdb文件，当父进程继续处理请求且遇到写请求时，复制资源，当子进程完成临时文件的写入时，用临时文件替换原来的历史文件
- RDB文件的载入是自动的
- 缺点是全量备份、有可能丢失最近一次快照期间的数据

## AOF

> Append Only File，保存写状态

- 记录下除了查询以外的所有数据变更指令

- 以append方式追加到AOF文件（增量）

- 配置

  ```
  appendonly yes // 开关
  appendfsync allways|everysec(默认)|no // 配置将备份文件写入磁盘的时机：每次更新都写入|每秒|由OS决定
  ```

- 日志重写（合并无用命令，只保留最新结果）解决文件不断增大的问题（创建，COW）
  - fork一个子进程
  - 子进程把新的AOF写到一个临时文件里面，不依赖原来的AOF文件
  - 主进程持续将新的变动同时写入内存以及原来的AOF文件
  - 主进程获取到子进程重写AOF完成的信号，往新的AOF同步增量变动
  - 使用新的AOF文件替换掉旧的AOF文件
- 有点：可读性高，数据不容易丢失
- 缺点：文件体积大，恢复时间长

## 数据恢复

1. 如果AOF文件存在，则直接加载AOF文件（日志回放）
2. 如果AOF文件不存在，尝试加载RDB文件
3. 如果两个文件都没有，无法进行数据恢复

## 混合模式

> RDB+AOF，redis4.0以后的默认方式

# Pipeline

> 类似于Linux的管道

- 批量执行指令，节省多次IO往返的时间

# 主从同步

## 原理

- 一个master写，多个slave读（读写分离）
- 最终一致性（主从数据最终趋于一致）

## 全量同步过程

1. slave发送sync命令到master
2. master启动一个后台进程，将redis中的数据快照保存到文件中
3. master将保存数据快照期间收到的写命令缓存起来
4. master完成第二步的写文件操作之后，将该文件发送给slave
5. slave将新的aof文件替换掉旧的aof文件
6. master将期间缓存到的增量写命令发送给客户端

## 增量同步

1. master接收到操作指令，判断是否需要传播到slave
2. 将操作记录追加到aof文件
3. 将操作传播到其它slave：对齐主从库，往响应缓存写入指令
4. 将缓存中的数据发送给slave

## 哨兵

> 解决主从同步master宕机之后主从切换的问题

- 独立的进程
- 监控多个主从服务器节点状态
- 通过api向管理员或者其它应用程序发送故障通知
- 自动故障迁移：主从切换（流言协议+投票机制）

### 流言协议

- 每个节点随机地与对方通信，最终所有节点的状态达成一致
- 种子节点定期随机向其他节点发送节点列表以及需要传播的消息
- 不保证信息一定会传递给所有节点，但是最终会趋于一致（类似于病毒传播）

# 集群

## 原理

- 分片：按照某种规则去划分数据，分散储存在多个节点上
- 常规的按照哈希无法实现节点的动态增删

### 一致性哈希算法

> 普通哈希算法的缺点：添加服务器时导致哈希值不一致，导致找不到正确的服务器，会导致缓存雪崩，一致性哈希算法可以减轻这种问题都不是完全解决

- 将哈希值空间组织成虚拟的圆环
- 将数据key使用相同的哈希函数计算出哈希值，顺时针选择最近一个服务器节点保存
- 缺点：哈希环的数据倾斜，大量数据分布在环的一侧。解决方法是引入虚拟节点，将一个真实节点缓存在环上各个位置，查找的时候，找到虚拟节点，再映射到真实的节点

# 缓存雪崩

- 如果缓存数据**设置的过期时间是相同**的，并且Redis恰好将这部分数据全部删光了。这就会导致在这段时间内，这些缓存**同时失效**，全部请求到数据库中
- 解决方法：在缓存的时候给过期时间加上一个**随机值**，这样就会大幅度的**减少缓存在同一时间过期**

# 缓存穿透

- 缓存穿透是指查询一个一定**不存在的数据**。由于缓存不命中，并且出于容错考虑，如果从**数据库查不到数据则不写入缓存**，这将导致这个不存在的数据**每次请求都要到数据库去查询**，失去了缓存的意义

- 解决缓存穿透也有两种方案：
  - 由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter**提前拦截**，不合法就不让这个请求到数据库层！
  - 当我们从数据库找不到的时候，我们也将这个**空对象设置到缓存里边去**。下次再请求的时候，就可以从缓存里边获取了。这种情况我们一般会将空对象设置一个**较短的过期时间**。

# 缓存击穿

- 缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞

# 缓存与数据库双写一致

## 问题

一般来说，执行更新操作时，我们会有两种选择：

1. 先操作数据库，再操作缓存

2. 先操作缓存，再操作数据库

无论我们选择哪个，我们都希望这**两个操作要么同时成功，要么同时失败**。所以这会演变成一个**分布式事务**的问题

## 先更新数据库，再删除缓存

- 如果原子性被破坏了：第一步成功(操作数据库)，第二步失败(删除缓存)，会导致**数据库里是新数据，而缓存里是旧数据**
- 如果在高并发的场景下，出现数据库与缓存数据不一致的**概率特别低**，也不是没有：
  - 缓存**刚好**失效
  - 线程A查询数据库，得一个旧值
  - 线程B将新值写入数据库
  - 线程B删除缓存
  - 线程A将查到的旧值写入缓存
- **删除缓存失败的解决思路**：
  - 将需要删除的key发送到消息队列中
  - 自己消费消息，获得需要删除的key
  - **不断重试删除操作，直到成功**

## 先删除缓存，再更新数据库

- 如果原子性被破坏了：第一步成功(删除缓存)，第二步失败(更新数据库)，数据库和缓存的数据还是一致的
- 并发环境下，会出现缓存不一致问题
  - 线程A删除了缓存
  - 线程B查询，发现缓存已不存在
  - 线程B去数据库查询得到旧值
  - 线程B将旧值写入缓存
  - 线程A将新值写入数据库

- 解决方法：将删除缓存、修改数据库、读取缓存等的操作积压到**队列**里边，实现**串行化**

# Copy On Write

- 在`继续提供服务`的情况下，如何保证`快照是精确的`？
- 写时复制：续提供服务，只有当有人修改当前内存数据时，才去复制被修改的内存页，用于生成快照。（内存复制的时间，向后推迟；内存粒度，拆解更细）

- Redis 中，执行 BGSAVE 命令，来生成 RDB 文件时，本质就是调用了 Linux 的系统调用 fork() 命令，Linux 下 fork() 系统调用，实现了 copy-on-write 写时复制
- Redis fork()出一个子进程后，主进程仍然处理客户端发来的读写请求，子进程完成读内存并写到rdb文件，在此过程中如果某部分数据子进程还未来得及写入rdb文件，主进程对其进行了写的更新操作，这部分写入的新数据仍然会被子进程写到rdb备份文件里