# 啥是微服务

> 微服务是由单一应用程序构成的小服务，拥有自己的进程与轻量化处理，服务依业务功能设计，以全自动的方式部署，与其他服务使用HTTP API通讯。同时，服务会使用最小规模的集中管理 （例如Docker）技术，服务可以用不同的编程语言与数据库等

## 单体应用

> 早期各大互联网公司的应用技术栈大致可分为LAMP（Linux + Apache + MySQL + PHP）和MVC（Spring + iBatis/Hibernate + Tomcat）两大流派，其均为单体应用服务

### 单体应用的缺点

1. 部署效率低下
2. 团队协作开发成本高
3. 系统高可用性差
4. 线上发布变慢

## 服务化

> 从单体应用的进程内调用变成远程RPC调用

- 服务化就是把传统的单机应用中通过JAR包依赖产生的本地方法调用，改造成通过RPC接口产生的远程方法调用

## 微服务化

- 服务拆分粒度更细
- 服务独立部署
- 服务独立维护
- 服务治理能力要求高

# 从单体应用走向服务化

## 拆分时机

- 一旦单体应用同时进行开发的人员超过10人，单体应用的缺点就会很明显，这个时候就该考虑进行服务化拆分了

## 拆分方式

- **纵向拆分**，是从业务维度进行拆分。标准是按照业务的关联程度来决定，关联比较密切的业务适合拆分为一个微服务，而功能相对比较独立的业务适合单独拆分为一个微服务
- **横向拆分**，是从公共且独立功能维度拆分。标准是按照是否有公共的被多个其他服务调用，且依赖的资源独立不与其他业务耦合
- 实际业务中这两种拆分方式一般是相互结合使用的，如果业务比较多分散，适合做纵向拆分。如果多个业务之间有公共模块耦合，适合把公共模块拆分出来，适合做横向拆分

## 服务拆分的前提条件

> 也就是微服务的基础设施

1. 服务如何定义
2. 服务如何发布和订阅
3. 服务如何监控
4. 服务如何治理
5. 故障如何定位

# 微服务架构（6大）

## 服务描述

- RESTful API：通常用于HTTP协议的服务描述，并且常用Wiki或者Swagger来进行管理
- XML配置：多用作RPC协议的服务描述，通过*.xml配置文件来定义接口名、参数以及返回值类型等
- IDL文件：IDL文件方式通常用作Thrift和gRPC这类跨语言服务调用框架中

## 注册中心

> 服务提供者将自己提供的服务以及地址登记到注册中心，服务消费者则从注册中心查询所需要调用的服务的地址，然后发起请求

- 主要流程
  - 服务提供者在启动时，根据服务发布文件中配置的发布信息向注册中心注册自己的服务。
  - 服务消费者在启动时，根据消费者配置文件中配置的服务信息向注册中心订阅自己所需要的服务。
  - 注册中心返回服务提供者地址列表给服务消费者。
  - 当服务提供者发生变化，比如有节点新增或者销毁，注册中心将变更通知给服务消费者。

## 服务框架

- 服务通信采用什么协议
- 数据传输采用什么方式
- 数据压缩采用什么格式

## 服务监控

- 指标收集
- 数据处理
- 数据展示

## 服务追踪

> 记录服务调用经过的每一层链路，以便进行问题追踪和故障定位

- 服务消费者发起调用前，会在本地按照一定的规则生成一个requestid，发起调用时，将requestid当作请求参数的一部分，传递给服务提供者。
- 服务提供者接收到请求后，记录下这次请求的requestid，然后处理请求。如果服务提供者继续请求其他服务，会在本地再生成一个自己的requestid，然后把这**两个**requestid都当作请求参数继续往下传递。

## 服务治理

> 服务监控能够发现问题，服务追踪能够定位问题所在，而解决问题就得靠服务治理了。服务治理就是通过一系列的手段来保证在各种意外情况下，服务调用仍然能够正常进行

- 单机故障
- 单IDC故障：互联网数据中心（Internet Data Center）
- 依赖服务不可用

# 发布和引用服务（服务描述）

- 通常情况下，如果只是企业内部之间的服务调用，并且都是Java语言的话，选择XML配置方式是最简单的。如果企业内部存在多个服务，并且服务采用的是不同语言平台，建议使用IDL文件方式进行描述服务。如果还存在对外开放服务调用的情形的话，使用RESTful API方式则更加通用

## RESTful API

- 主要被用作HTTP或者HTTPS协议的接口定义，即使在非微服务架构体系下，也被广泛采用

- 如果不仅需要在业务部门内部提供服务，还需要向其他业务部门提供服务，甚至开放给外网提供服务，这时候采用HTTP协议就比较合适，也省去了沟通服务协议的成本

## XML配置

- 一般流程
  - 服务提供者定义接口，并实现接口。
  - 服务提供者进程启动时，通过加载server.xml配置文件将接口暴露出去。
  - 服务消费者进程启动时，通过加载client.xml配置文件来引入要调用的接口。

- 一般是私有RPC框架会选择XML配置这种方式来描述接口，因为私有RPC协议的性能要比HTTP协议高，所以在对性能要求比较高的场景下，采用XML配置的方式比较合适。但这种方式对业务代码侵入性比较高，XML配置有变更的时候，服务消费者和服务提供者都要更新，所以适合公司内部联系比较紧密的业务之间采用
- 对于XML配置方式的服务描述，一旦应用到多个部门之间的接口格式约定，如果有变更，最好是新增接口，不到万不得已不要对原有的接口格式做变更

## IDL文件

> IDL就是接口描述语言（interface description language）的缩写，通过一种中立的方式来描述接口，使得在不同的平台上运行的对象和不同语言编写的程序可以相互通信交流

- 在描述接口定义时，IDL文件需要对接口返回值进行详细定义。如果接口返回值的字段比较多，并且经常变化时，采用IDL文件方式的接口定义就不太合适了。一方面可能会造成IDL文件过大难以维护，另一方面只要IDL文件中定义的接口返回值有变更，都需要同步所有的服务消费者都更新，管理成本就太高了

# 注册与发现服务

## 注册中心原理

- RPC Server提供服务，在启动时，根据服务发布文件server.xml中的配置的信息，向Registry注册自身服务，并向Registry定期发送心跳汇报存活状态。
- RPC Client调用服务，在启动时，根据服务引用文件client.xml中配置的信息，向Registry订阅服务，把Registry返回的服务节点列表缓存在本地内存中，并与RPC Sever建立连接。
- 当RPC Server节点发生变更时，Registry会同步变更，RPC Client感知后会刷新本地内存中缓存的服务节点列表。
- RPC Client从本地缓存的服务节点列表中，基于负载均衡算法选择一台RPC Sever发起调用。

## 注册中心

### 注册中心API

1. 服务注册接口——提供者
2. 服务反注册接口（注销）——提供者
3. 心跳汇报接口——提供者
4. 服务订阅接口——消费者
5. 服务变更查询接口——消费者，获取最新的可用服务节点列表
6. 服务查询接口——管理者，查询注册中心当前注册了哪些服务信息
7. 服务修改接口——管理者，修改注册中心中某一服务的信息

### 集群部署

- 注册中心一般都是采用集群部署来保证高可用性，并通过分布式一致性协议来确保集群中不同节点之间的数据保持一致
- 高可用与数据一致性
  - 每个Server在内存中存储了一份数据，Client的读请求可以请求任意一个Server
  - ZooKeeper启动时，将从实例中选举一个leader（Paxos协议）
  - Leader负责处理数据更新等操作（ZAB协议）
  - 一个更新操作成功，当且仅当大多数Server在内存中成功修改 

### 目录存储

> 注册中心存储服务信息一般采用层次化的目录结构

- 每个目录在ZooKeeper中叫作znode，并且其有一个唯一的路径标识。
- znode可以包含数据和子znode。
- znode中的数据可以有多个版本，比如某一个znode下存有多个数据版本，那么查询这个路径下的数据需带上版本信息。

### 服务健康状态检测

> 对服务提供者节点的健康状态检测功能，这样才能保证注册中心里保存的服务节点都是可用的

- 心跳检测

### 服务状态变更通知

> 一旦注册中心探测到有服务提供者节点新加入或者被剔除，就必须立刻通知所有订阅该服务的服务消费者，刷新本地缓存的服务节点信息，确保服务调用不会请求不可用的服务提供者节点

### 白名单机制

> 注册中心可以提供一个白名单机制，只有添加到注册中心白名单内的RPC Server，才能够调用注册中心的注册接口，这样的话可以避免测试环境中的节点意外跑到线上环境中去

# RPC远程服务调用（服务框架）

## 客户端和服务端如何建立网络连接

- HTTP通信
- Socket通信

## 服务端如何处理请求

- 同步阻塞方式（BIO）
- 同步非阻塞方式 (NIO)：把多个I/O的阻塞复用到同一个select的阻塞上，从而使系统在单线程的情况下可以同时处理多个客户端请求
- 异步非阻塞方式（AIO）

## 数据传输采用什么协议

- 最常用的有HTTP协议，它是一种开放的协议，各大网站的服务器和浏览器之间的数据传输大都采用了这种协议
- 定制的私有协议，比如阿里巴巴开源的Dubbo协议，也可以用于服务端和客户端之间的数据传输

## 数据该如何序列化和反序列化

- 文本类如XML/JSON等，二进制类如PB/Thrift
- 要素
  - 支持数据结构类型的丰富度
  - 跨语言支持
  - 性能

# 监控微服务调用

## 监控对象

1. 用户端监控：指业务直接对用户提供的功能的监控
2. 接口监控：指业务提供的功能所依赖的具体RPC接口的监控
3. 资源监控：指某个接口依赖的资源的监控
4. 基础监控：指对服务器本身的健康状况的监控

## 监控指标

1. 请求量。请求量监控分为两个维度，一个是实时请求量，一个是统计请求量。实时请求量用QPS（Queries Per Second）即每秒查询次数来衡量，它反映了服务调用的实时变化情况。统计请求量一般用PV（Page View）即一段时间内用户的访问量来衡量，比如一天的PV代表了服务一天的请求量
2. 响应时间
3. 错误率：错误率的监控通常用一段时间内调用失败的次数占调用总次数的比率来衡量

## 监控维度

1. 全局维度
2. 分机房维度
3. 单机维度
4. 时间维度
5. 核心维度

## 监控系统原理

1. 数据采集：服务主动上报；代理收集
2. 数据传输：UDP传输；Kafka传输
3. 数据处理：即数据聚合，接口维度聚合；机器维度聚合
4. 数据展示：以Dashboard的方式可视化展示给用户

# 追踪微服务调用

## 服务追踪的作用

1. 优化系统瓶颈
2. 优化链路调用
3. 生成网络拓扑
4. 透明传输数据

## 服务追踪系统原理

- 核心理念是**调用链**：通过一个全局唯一的ID将分布在各个服务节点上的同一次请求串联起来，从而还原原有的调用关系，可以追踪系统问题、分析调用数据并统计各种系统指标。后面的诞生各种服务追踪系统都是基于Dapper衍生出来的，比较有名的有Twitter的Zipkin、阿里的鹰眼、美团的MTrace等
- traceId，用于标识某一次具体的请求ID。当用户的请求进入系统后，会在RPC调用网络的第一层生成一个全局唯一的traceId，并且会随着每一层的RPC调用，不断往后传递，这样的话通过traceId就可以把一次用户请求在系统中调用的路径串联起来
- spanId，用于标识一次RPC调用在分布式请求中的位置，通过spanId就可以定位某一次RPC请求在系统调用中所处的位置，以及它的上下游依赖分别是谁
- annotation，用于业务自定义埋点数据，可以是业务感兴趣的想上传到后端的数据，比如一次请求的用户UID

# 服务治理

## 节点管理

1. 注册中心主动摘除机制：将故障节点从服务列表中摘除，并把最近的可用服务节点列表推送给服务消费者
2. 服务消费者摘除机制：将存活探测机制用在服务消费者这一端=，如果服务消费者调用服务提供者节点失败，就将这个节点从内存中保存的可用服务提供者节点列表中移除

## 负载均衡

1. 随机算法
2.  **轮询算法**
3. **最少活跃调用算法**：在服务消费者这一端的内存里动态维护着同每一个服务节点之间的连接数
4. 一致性Hash算法

## 服务路由

> 注册中心也可以存配置，两者可以分开部署也可以部署在一起

1. **静态配置**
2. **动态配置**

## 服务容错

1. FailOver：失败自动切换，这种策略要求服务调用的操作必须是幂等的
2. FailBack：失败通知，服务消费者调用失败或者超时后，不再重试，而是根据失败的详细信息，来决定后续的执行策略
3. FailCache：失败缓存，服务消费者调用失败或者超时后，不立即发起重试，而是隔一段时间后再次尝试发起调用（类似于拥塞避免）
4. FailFast：快速失败，服务消费者调用一次失败后，不再重试（一般非核心业务的调用，会采用快速失败策略）

---

# Dubbo框架

## 服务发布与引用

- 服务提供者配置XML，其中“dubbo:service”开头的配置项声明了服务提供者要发布的接口，“dubbo:protocol”开头的配置项声明了服务提供者要发布的接口的协议以及端口号。然后基于扩展点自适应机制，通过URL的“dubbo://”协议头识别，就会调用DubboProtocol的export()方法，打开服务端口，就可以把服务暴露到指定端口了
- 服务消费者配置XML，其中“dubbo:reference”开头的配置项声明了服务消费者要引用的服务。然后基于扩展点自适应机制，通过URL的“dubbo://”协议头识别，就会调用DubboProtocol的refer()方法，得到服务的引用，完成服务引用过程

## 服务注册与发现

- 服务提供者注册服务，“dubbo://registry”开头的配置项声明了注册中心的地址。然后基于扩展点自适应机制，通过URL的“registry://”协议头识别，就会调用RegistryProtocol的export()方法，将export参数中的提供者URL，注册到注册中心。
- 服务消费者发现服务，“dubbo://registry”开头的配置项声明了注册中心的地址，然后基于扩展点自适应机制，通过URL的“registry://”协议头识别，就会调用RegistryProtocol的refer()方法，基于refer参数中的条件，查询服务的地址

## 服务调用

- 在服务端和客户端的XML配置中添加通信框架的配置项（如netty）、数据传输协议（Dubbo不仅支持私有的Dubbo协议，还支持其他协议比如Hessian、RMI、HTTP、Web Service、Thrift等）、数据序列化和反序列协议（Dubbo同样也支持多种序列化格式，比如Dubbo、Hession 2.0、JSON、Java、Kryo以及FST等），基于扩展点自适应机制，客户端和服务端之间的调用会通过指定的框架来建立连接

## 服务监控

- 在Dubbo框架中，无论是服务提供者还是服务消费者，在执行服务调用的时候，都会经过Filter调用链拦截，来完成一些特定功能

## 服务治理

- ![avatar](./dubbo服务治理.jpg)

# 服务发布与引用实践

## XML配置方式的服务发布和引用流程

1. 服务提供者定义接口：服务提供者发布服务之前首先要定义接口，声明接口名、传递参数以及返回值类型，然后**把接口打包成JAR包发布出去**

2. 服务提供者发布接口：服务提供者发布的接口是通过在服务发布配置文件中定义接口来实现的。服务发布者在进程启动的时候，会加载配置文件，把接口对外暴露出去

3. 服务消费者引用接口：服务消费者引用接口是通过在服务引用配置文件中定义要引用的接口，并**把包含接口定义的JAR包引入到代码依赖中**

## 服务发布和引用的那些坑

1. 服务消费者对服务的认知水平不一，有可能没有配置参数。所以需要在服务发布的配置文件中预定义好类似超时重试次数，即使服务消费者没有在服务引用配置文件中定义，也能继承服务提供者的定义（服务发布预定义配置）。
2. 如果配置文件很大且保存在注册中心，消费者拉取时会导致网络抖动。最好的办法是把服务发布端的详细服务配置信息转移到服务引用端，这样的话注册中心中就不需要存储服务提供者发布的详细服务配置信息了（服务引用定义配置）

# 注册中心落地

## 注册中心如何存储服务信息

- 注册中心存储的服务信息一般包含三部分内容：分组、服务名以及节点信息，节点信息又包括节点地址和节点其他信息（服务信息除了包含节点信息（IP和端口号）以外，还包含其他一些信息，比如请求失败时重试的次数、请求结果是否压缩等信息）
- 分组的维度
  - 核心与非核心，从业务的核心程度来分。
  - 机房，从机房的维度来分。
  - 线上环境与测试环境，从业务场景维度来区分。
- 具体存储的时候，一般是按照“服务-分组-节点信息”三层结构来存储

## 注册中心如何工作

### 如何注册节点

1. 首先查看要注册的节点是否在白名单内？如果不在就抛出异常，在的话继续下一步。
2. 其次要查看注册的Cluster（服务的接口名）是否存在？如果不存在就抛出异常，存在的话继续下一步。
3. 然后要检查Service（服务的分组）是否存在？如果不存在则抛出异常，存在的话继续下一步。
4. 最后将节点信息添加到对应的Service和Cluster下面的存储中

### 如何反注册

1. 查看Service（服务的分组）是否存在，不存在就抛出异常，存在就继续下一步。
2. 查看Cluster（服务的接口名）是否存在，不存在就抛出异常，存在就继续下一步。
3. 删除存储中Service和Cluster下对应的节点信息。
4. 更新Cluster的sign值。

### 如何查询节点信息

1. 首先从localcache（本机内存）中查找，如果没有就继续下一步
2. 接着从snapshot（本地快照）中查找，如果没有就继续下一步

### 如何订阅服务变更

1. 服务消费者从注册中心获取了服务的信息后，就订阅了服务的变化，会在本地保留Cluster的sign值
2. 服务消费者每隔一段时间，调用getSign()函数，从注册中心获取服务端该Cluster的sign值，并与本地保留的sign值做对比，如果不一致，就从服务端拉取新的节点信息，并更新localcache和snapshot

## 注册与发现的几个问题

1. 多注册中心：对于服务消费者来说，要能够同时从多个注册中心订阅服务；对于服务提供者来说，要能够同时向多个注册中心注册服务
2. 并行订阅服务
3. 批量反注册服务：对于下线机器、节点销毁的场景，通过调用注册中心提供的批量反注册接口，一次调用就可以把该节点上提供的所有服务同时反注册掉，从而避免了“僵尸节点”的出现
4. 服务变更信息增量更新：为了减少服务消费者从注册中心中拉取的服务可用节点信息的数据量，这个时候可以通过增量更新的方式，注册中心只返回变化的那部分节点信息，尤其在只有少数节点信息变更时，此举可以大大减少服务消费者从注册中心拉取的数据量，从而最大程度避免产生网络风暴

## 开源服务注册中心选型

## 两种典型的注册中心实现

- 应用内的解决方案一般适用于服务提供者和服务消费者同属于一个技术体系；应用外的解决方案一般适合服务提供者和服务消费者采用了不同技术体系的业务场景，比如服务提供者提供的是C++服务，而服务消费者是一个Java应用，这时候采用应用外的解决方案就不依赖于具体一个技术体系。
- 对于容器化后的云应用来说，一般不适合采用应用内SDK的解决方案，因为这样会侵入业务，而应用外的解决方案正好能够解决这个问题。

### 应用内

> 注册中心提供服务端和客户端的SDK，业务应用通过引入注册中心提供的SDK，通过SDK与注册中心交互，来实现服务的注册和发现，最典型的案例要属Netflix开源的Eureka

- Eureka Server：注册中心的服务端，实现了服务信息注册、存储以及查询等功能。
- 服务端的Eureka Client：集成在服务端的注册中心SDK，服务提供者通过调用SDK，实现服务注册、反注册等功能。
- 客户端的Eureka Client：集成在客户端的注册中心SDK，服务消费者通过调用SDK，实现服务订阅、服务更新等功能。

### 应用外

> 业务应用本身不需要通过SDK与注册中心打交道，而是通过其他方式与注册中心交互，间接完成服务注册与发现，最典型的案例是开源注册中心Consul

- Consul：注册中心的服务端，实现服务注册信息的存储，并提供注册和发现服务。
- Registrator：一个开源的第三方服务管理器项目，它通过监听服务部署的Docker实例是否存活，来负责服务提供者的注册和销毁。
- Consul Template：定时从注册中心服务端获取最新的服务提供者节点列表并刷新LB配置（比如Nginx的upstream），这样服务消费者就通过访问Nginx就可以获取最新的服务提供者信息。

## 注册中心选型要考虑的两个问题

###  高可用性

- 集群部署
- 多IDC部署

### 数据一致性

> 在一个分布式系统里面，包含了多个节点，节点之间通过网络连通在一起。正常情况下，通过网络，从一个节点可以访问任何别的节点上的数据。但是有可能出现网络故障，导致整个网络被分成了互不连通的区域，这就叫作分区。
>
> 一旦出现分区，那么一个区域内的节点就没法访问其他节点上的数据了，最好的办法是把数据复制到其他区域内的节点，这样即使出现分区，也能访问任意区域内节点上的数据，这就是分区容错性。
>
> 但是把数据复制到多个节点就可能出现数据不一致的情况，这就是一致性。
>
> 要保证一致，就必须等待所有节点上的数据都更新成功才可用，这就是可用性

- CP型注册中心，牺牲可用性来保证数据强一致性，典型的例子就是ZooKeeper，etcd，Consul。
- AP型注册中心，牺牲一致性来保证可用性，典型的例子就是Eureka。
- 对于注册中心来说，最主要的功能是服务的注册和发现，在网络出现问题的时候，可用性的需求要远远高于数据一致性。即使因为数据不一致，注册中心内引入了不可用的服务节点，也可以通过其他措施来避免，比如客户端的快速失败机制等，只要实现最终一致性，对于注册中心来说就足够了。因此，选择AP型注册中心，一般更加合适

# 开源RPC框架选型

> 开源RPC框架主要分为两类：一类是跟某种特定语言平台绑定的，如Dubbo、Motan、Tars、Spring Cloud，另一类是与语言无关即跨语言平台的，如gRPC、Thrift

## Dubbo

- ![avatar](dubbo架构.jpg)

## Motan

- 只支持Java语言实现
- ![avatar](motan架构.jpg)

## Tars

- 腾讯开源
- ![avatar](tars架构.jpg)

## Spring Cloud

- 基于Spring Boot进行开发的，Spring Cloud利用Spring Boot特性整合了开源行业中优秀的组件，整体对外提供了一套在微服务架构中服务治理的解决方案
- ![avatar](springcloud架构.jpg)

## gRPC

- 通过IDL（Interface Definition Language）文件定义服务接口的参数和返回值类型，然后通过代码生成程序生成服务端和客户端的具体实现代码，这样在gRPC里，客户端应用可以像调用本地对象一样调用另一台服务器上对应的方法
- ![avatar](grpc架构.jpg)

- 特性
  - 通信协议采用了HTTP/2
  - IDL使用了ProtoBuf
  - 多语言支持，能够基于多种语言自动生成对应语言的客户端和服务端的代码

## Thrift

- Thrift也有一套自己的接口定义语言IDL，可以通过代码生成器，生成各种编程语言的Client端和Server端的SDK代码，这样就保证了不同语言之间可以相互通信
- 支持多种序列化格式：如Binary、Compact、JSON、Multiplexed等。
- 支持多种通信方式：如Socket、Framed、File、Memory、zlib等。
- 服务端支持多种处理方式：如Simple 、Thread Pool、Non-Blocking等。
- ![avatar](thrift架构.jpg)

# 监控系统

> 比较流行的开源监控系统实现方案主要有两种：以ELK为代表的集中式日志解决方案，以及Graphite、TICK和Prometheus等为代表的时序数据库解决方案

## ELK

- ELK是Elasticsearch、Logstash、Kibana三个开源软件产品首字母的缩写，它们三个通常配合使用
- Logstash负责数据收集和传输，它支持动态地从各种数据源收集数据，并对数据进行过滤、分析、格式化等，然后存储到指定的位置。
- Elasticsearch负责数据处理，它是一个开源分布式搜索和分析引擎，具有可伸缩、高可靠和易管理等特点，基于Apache Lucene构建，能对大容量的数据进行接近实时的存储、搜索和分析操作，通常被用作基础搜索引擎。
- Kibana负责数据展示，也是一个开源和免费的工具，通常和Elasticsearch搭配使用，对其中的数据进行搜索、分析并且以图表的方式展示。
- 为了减少Logstash对服务器的影响，引入了Beats，Beats所占系统的CPU和内存几乎可以忽略不计，可以安装在每台服务器上做轻量型代理，从成百上千或成千上万台机器向Logstash或者直接向Elasticsearch发送数据
- ![avatar](BELK架构.jpg)

## Graphite

- Carbon：主要作用是接收被监控节点的连接，收集各个指标的数据，将这些数据写入carbon-cache并最终持久化到Whisper存储文件中去。
- Whisper：一个简单的时序数据库，主要作用是存储时间序列数据，可以按照不同的时间粒度来存储数据，比如1分钟1个点、5分钟1个点、15分钟1个点三个精度来存储监控数据。
- Graphite-Web：一个Web App，其主要功能绘制报表与展示，即数据展示。为了保证Graphite-Web能及时绘制出图形，Carbon在将数据写入Whisper存储的同时，会在carbon-cache中同时写入一份数据，Graphite-Web会先查询carbon-cache，如果没有再查询Whisper存储。
- ![avatar](Graphite架构.jpg)

- Graphite自身并不包含数据采集组件，但可以接入StatsD等开源数据采集组件来采集数据，再传送给Carbon

## TICK

- TICK是Telegraf、InfluxDB、Chronograf、Kapacitor四个软件首字母的缩写，是由InfluxData开发的一套开源监控工具栈
- Telegraf负责数据收集，InfluxDB负责数据存储，Chronograf负责数据展示，Kapacitor负责数据告警
- ![avatar](TICK架构.jpg)

## Prometheus

- Prometheus Server定期从配置好的jobs或者exporters中拉取metrics信息，或者接收来自Pushgateway发过来的metrics信息。
- Prometheus Server把收集到的metrics信息存储到时间序列数据库中，并运行已经定义好的alert.rules，向Alertmanager推送警报。
- Alertmanager根据配置文件，对接收的警报进行处理，发出告警。
- 通过Prometheus web UI进行可视化展示。

- ![avatar](Prometheus架构.jpg)

# 服务追踪系统

- 比较有名的服务追踪系统实现有阿里的鹰眼、Twitter开源的OpenZipkin，还有Naver开源的Pinpoint，它们都是受Google发布的Dapper论文启发而实现的。其中阿里的鹰眼解决方案没有开源

##  OpenZipkin

- Collector：负责收集探针Reporter埋点采集的数据，经过验证处理并建立索引。
- Storage：存储服务调用的链路数据，默认使用的是Cassandra，是因为Twitter内部大量使用了Cassandra，你也可以替换成Elasticsearch或者MySQL。
- API：将格式化和建立索引的链路数据以API的方式对外提供服务，比如被UI调用。
- UI：以图形化的方式展示服务调用的链路数据。

- ![avatar](OpenZipkin架构.jpg)

## Pinpoint

- Pinpoint Agent：通过Java字节码注入的方式，来收集JVM中的调用数据，通过UDP协议传递给Collector，数据采用Thrift协议进行编码。
- Pinpoint Collector：收集Agent传过来的数据，然后写到HBase Storgage。
- HBase Storage：采用HBase集群存储服务调用的链路信息。
- Pinpoint Web UI：通过Web UI展示服务调用的详细链路信息。

- ![avatar](Pinpoint架构.jpg)

# 识别服务节点是否存活

## 心跳开关保护机制

> 在网络频繁抖动时，服务提供者向注册中心汇报心跳信息可能会失败，如果在规定的时间内，注册中心都没有收到服务提供者的心跳信息，就会把这个节点从可用节点列表中移除。更糟糕的是，在服务池拥有上百个节点的的时候，每个节点都可能会被移除，导致注册中心可用节点的状态一直在变化

- 即使在网络频繁抖动的时候，服务消费者也不至于同时去请求注册中心获取最新的服务节点信息

## 服务节点摘除保护机制

> 如果遇到网络问题，大批服务提供者节点汇报给注册中心的心跳信息都可能会传达失败，注册中心就会把它们都从可用节点列表中移除出去，造成剩下的可用节点难以承受所有的调用，引起“雪崩”

- 根据实际业务的情况，设定一个阈值比例，即使遇到刚才说的这种情况，注册中心也不能摘除超过这个阈值比例的节点
- 这个阈值比例可以根据实际业务的冗余度来确定，我通常会把这个比例设定在20%，就是说注册中心不能摘除超过20%的节点。因为大部分情况下，节点的变化不会这么频繁，只有在网络抖动或者业务明确要下线大批量节点的情况下才有可能发生

## 静态注册中心

- 服务消费者端根据调用服务提供者是否成功来判定服务提供者是否可用。如果服务消费者调用某一个服务提供者节点连续失败超过一定次数，可以在本地内存中将这个节点标记为不可用。并且每隔一段固定时间，服务消费者都要向标记为不可用的节点发起保活探测，如果探测成功了，就将标记为不可用的节点再恢复为可用状态，重新发起调用

# 负载均衡算法

## 常见的负载均衡算法

- 随机算法
- **轮询算法**
- **加权轮询算法**：加权轮询算法是生成一个节点序列，该序列里有n个节点，n是所有节点的权重之和
- **最少活跃连接算法**：在实现时，需要记录跟每一个节点的连接数，这样在选择节点时，才能比较出连接数最小的节点。

- **一致性hash算法**

- 自适应最优选择算法：在客户端本地维护一份同每一个服务节点的性能统计快照，并且每隔一段时间去更新这个快照。在发起请求时，根据“二八原则”，把服务节点分成两部分，找出20%的那部分响应最慢的节点，然后降低权重。这样的话，客户端就能够实时的根据自身访问每个节点性能的快慢，动态调整访问最慢的那些节点的权重，来减少访问量，从而可以优化长尾请求（自适应最优选择算法是对加权轮询算法的改良，可以看作是一种动态加权轮询算法）

# 服务路由

> 服务路由就是服务消费者在发起服务调用时，必须根据特定的规则来选择服务节点，从而满足某些特定的需求

## 服务路由的应用场景

- 分组调用，服务部署在不同的DIC或者不同的云服务
- 灰度发布，也叫金丝雀部署，在一小部分规模的服务节点上先发布服务，然后验证功能是否正常。如果正常的话就继续扩大发布范围；如果不正常的话，就需要排查问题，解决问题后继续发布
- 流量切换，按照某个指令，能够把原来调用这个机房服务的流量切换到其他正常的机房
- 读写分离

## 服务路由的规则

### 条件路由

- 排除某个服务节点
- 白名单和黑名单功能
- 机房隔离
- 读写分离

### 脚本路由

> 脚本路由是基于脚本语言的路由规则，常用的脚本语言比如JavaScript、Groovy、JRuby等

## 服务路由的获取方式

> 服务消费者获取路由规则

- 本地配置
- 配置中心管理
- 动态下发，通过服务治理平台修改路由规则，服务治理平台调用配置中心接口，把修改后的路由规则持久化到配置中心。因为服务消费者订阅了路由规则的变更，于是就会从配置中心获取最新的路由规则，按照最新的路由规则来执行
- 这三种方式也可以一起使用，这个时候服务消费者的判断优先级是本地配置>动态下发>配置中心管理

# 服务端故障处理

## 集群故障

### 限流

- 根据系统的最大容量，给系统设置一个阈值，超过这个阈值的请求会被自动抛弃，这样的话可以最大限度地保证系统提供的服务正常；还要针对系统中每个服务的请求量也设置一个阈值，超过这个阈值的请求也要被自动抛弃，这样的话不至于因为一个服务影响了其他所有服务
- 可以用两个指标来衡量服务的请求量，一个是QPS即每秒请求量，一个是工作线程数。不过QPS因为不同服务的响应快慢不同，所以系统能够承载的QPS相差很大，因此一般选择工作线程数来作为限流的指标

### 降级

- 通过停止系统中的某些功能，来保证系统整体的可用性。降级可以说是一种被动防御的措施，因为它一般是系统已经出现故障后所采取的一种止损措施
- 降级一般可以通过开关实现，开关一般用在两种地方，一种是新增的业务逻辑，因为新增的业务逻辑相对来说不成熟，往往具备一定的风险，所以需要加开关来控制新业务逻辑是否执行；另一种是依赖的服务或资源，因为依赖的服务或者资源不总是可靠的，所以最好是有开关能够控制是否对依赖服务或资源发起调用，来保证即使依赖出现问题，也能通过降级来避免影响
- 在实际业务应用的时候，降级要按照对业务的影响程度进行分级，一般分为三级，对业务的影响递增

## 单IDC故障

> 采用多IDC部署的最大好处就是当有一个IDC发生故障时，可以把原来访问故障IDC的流量切换到正常的IDC，来保证业务的正常访问

### 基于DNS解析的流量切换

- 解析可能延迟，网络延迟可能会变长

###  基于RPC分组的流量切换

- 对于一个服务来说，如果是部署在多个IDC的话，一般每个IDC就是一个分组。假如一个IDC出现故障，那么原先路由到这个分组的流量，就可以通过向配置中心下发命令，把原先路由到这个分组的流量全部切换到别的分组，这样的话就可以切换故障IDC的流量了

## 单机故障

- 处理单机故障一个有效的办法就是自动重启。具体来讲，你可以设置一个阈值，比如以某个接口的平均耗时为准，当监控单机上某个接口的平均耗时超过一定阈值时，就认为这台机器有问题，这个时候就需要把有问题的机器从线上集群中摘除掉，然后在重启服务后，重新加入到集群中
- 为了防止网络抖动造成的接口超时从而触发自动重启。一种方法是在收集单机接口耗时数据时，多采集几个点，比如每10s采集一个点，采集5个点，当5个点中有超过3个点的数据都超过设定的阈值范围，才认为是真正的单机问题，这时会触发自动重启策略
- 为了防止某些特殊情况下，短时间内被重启的单机过多，造成整个服务池可用节点数太少，最好是设置一个可重启的单机数量占整个集群的最大比例，一般这个比例不要超过10%

# 服务调用失败处理

> 服务的远程调用引入了两个不确定的因素，一个是调用的执行是在服务提供者一端，即使服务消费者本身是正常的，服务提供者也可能由于各种原因失败。另一个不确定因素是调用发生在两台机器之间，网络传输也有可能导致服务调用失败。

## 超时

- 服务调用都要设置一个超时时间，以避免依赖的服务迟迟没有返回调用结果，把服务消费者拖死。超时时间根据正常情况下，服务提供者的服务水平来决定

## 重试

- 从概率论的角度来讲，假如一次服务调用失败的概率为1%，那么连续两次服务调用失败的概率就是0.01%，失败率降低到原来的1%
- 设置一个服务调用超时后的重试次数。假如某个服务调用的超时时间设置为100ms，重试次数设置为1，那么当服务调用超过100ms后，服务消费者就会立即发起第二次服务调用，而不会再等待第一次调用返回的结果了

## 双发

- 一个简单的提高服务调用成功率的办法就是每次服务消费者要发起服务调用的时候，都同时发起两次服务调用，一方面可以提高调用的成功率，另一方面两次服务调用哪个先返回就采用哪次的返回结果，平均响应时间也要比一次调用更快，这就是双发
- 一个更为聪明的双发，即“备份请求”（Backup Requests），它的大致思想是服务消费者发起一次服务调用后，在给定的时间内如果没有返回请求结果，那么服务消费者就立刻发起另一次服务调用。这里需要注意的是，这个设定的时间通常要比超时时间短得多

## 熔断

> 熔断可以理解为间歇性的降级，之后会探测服务是否恢复自动恢复降级，而降级一般指的是一次性的中断对服务的调用，需要人为再主动恢复降级

- 熔断就是把客户端的每一次服务调用用断路器封装起来，通过断路器来监控每一次服务调用。如果某一段时间内，服务调用失败的次数达到一定阈值，那么断路器就会被触发，后续的服务调用就直接返回，也就不会再向服务提供者发起请求了
- 断路器的三种状态：Closed状态->Open状态->Half Open状态->Closed状态
- Netflix开源的Hystrix是最经典的断路器实现。Hystrix的断路器也包含三种状态：关闭、打开、半打开。Hystrix会把每一次服务调用都用HystrixCommand封装起来，它会实时记录每一次服务调用的状态，包括成功、失败、超时还是被线程拒绝。当一段时间内服务调用的失败率高于设定的阈值后，Hystrix的断路器就会进入进入打开状态，新的服务调用就会直接返回，不会向服务提供者发起调用。再等待设定的时间间隔后，Hystrix的断路器又会进入半打开状态，新的服务调用又可以重新发给服务提供者了；如果一段时间内服务调用的失败率依然高于设定的阈值的话，断路器会重新进入打开状态，否则的话，断路器会被重置为关闭状态

# 管理服务配置

> 曾经的单体应用只需要管理一套配置；而拆分为微服务后，每一个系统都有自己的配置，并且都各不相同，而且因为服务治理的需要，有些配置还需要能够动态改变，以达到动态降级、切流量、扩缩容等目的

## 本地配置

- 服务配置管理最简单的方案就是把配置当作代码同等看待，随着应用程序代码一起发布，或者抽取成为独立的配置文件。
- 无论是把配置定义在代码里，还是把配置从代码中抽离出来，都相当于把配置存在了应用程序的本地。这样做的话，如果需要修改配置，就需要重新走一遍代码或者配置的发布流程，在实际的线上业务当中，这是一个很重的操作，往往相当于一次上线发布过程。

## 配置中心

- 配置中心的思路就是把服务的各种配置，如代码里配置的各种参数、服务降级的开关甚至依赖的资源等都在一个地方统一进行管理。服务启动时，可以自动从配置中心中拉取所需的配置，并且如果有配置变更的情况，同样可以自动从配置中心拉取最新的配置信息，服务无须重新发布
- 一般来讲，配置中心存储配置是按照Group来存储的，同一类配置放在一个Group下，以K, V键值对存储
- 配置注册功能
- 配置反注册功能
- 配置查看功能
- 配置变更订阅功能

### 配置中心的典型应用场景

- 资源服务化
- 业务动态降级
- 分组流量切换

## 开源配置中心与选型

- Spring Cloud Config。Spring Cloud中使用的配置中心组件，只支持Java语言，配置存储在git中，变更配置也需要通过git操作，如果配置中心有配置变更，需要手动刷新。
- [Disconf](https://github.com/knightliao/disconf)。百度开源的分布式配置管理平台，只支持Java语言，基于Zookeeper来实现配置变更实时推送给订阅的客户端，并且可以通过统一的管理界面来修改配置中心的配置。
- Apollo。携程开源的分布式配置中心，支持Java和.Net语言，客户端和配置中心通过HTTP长连接实现实时推送，并且有统一的管理界面来实现配置管理。
- Spring Cloud Config作为配置中心的功能比较弱，只能通过git命令操作，而且变更配置的话还需要手动刷新，如果不是采用Spring Cloud框架的话不建议选择。而Disconf和Apollo的功能都比较强大，在国内许多互联网公司内部都有大量应用，其中Apollo对Spring Boot的支持比较好，如果应用本身采用的是Spring Boot开发的话，集成Apollo会更容易一些

# 服务治理平台

> 微服务治理平台就是**与服务打交道的统一入口**，无论是开发人员还是运维人员，都能通过这个平台对服务进行各种操作

- ![avatar](服务治理平台.jpg)

## 微服务治理平台的基本功能

### 服务管理

- 服务上下线
- 节点添加/删除
- 服务查询
- 服务节点查询

### 服务治理

- 限流
- 降级
- 切换流量

### 服务监控

- 整体监控，比如服务依赖拓扑图，将整个系统内服务间的调用关系和依赖关系进行可视化的展示
- 具体服务监控，比如服务的QPS、AvgTime、P999等监控指标

### 问题定位

- 宏观层面，即通过服务监控来发觉异常，比如某个服务的平均耗时异常导致调用失败
- 微观层面，即通过服务追踪来具体定位一次用户请求失败具体是因为服务调用全链路的哪一层导致的

### 日志查询

### 服务运维

- 发布部署
- 扩缩容

## 搭建微服务治理平台

- ![avatar](微服务治理平台架构.jpg)

- **Web Portal**，也就是微服务治理平台的前端展示层
  - 服务管理界面
  - 服务治理界面
  - 服务监控界面
  - 服务运维界面
- **API**。也就是微服务治理平台的后端服务层，这一层对应的需要提供Web Portal接口以调用
  - 添加服务接口
  - 删除服务接口
  - 服务降级/限流/切流量接口
  - 服务扩缩容接口
  - 服务部署接口

- **DB**。也就是微服务治理平台的数据存储层，因为微服务治理平台不仅需要调用其他组件提供的接口，还需要存储一些基本信息
  - 用户权限
  - 操作记录
  - 元数据：主要是用来把服务在各个系统中对应的记录映射到微服务治理平台中，统一进行管理。比如某个服务在监控系统里可能有个特殊标识，在注册中心里又使用了另外一个标识，为了统一就需要在微服务治理平台统一进行转换，然后进行数据串联

# 微服务架构落地

## 组建合适的技术团队

- 只有架构师适合做微服务架构的开发，但是这支团队需要有业务开发人员，避免脱离实际

## 从一个案例入手

- 首先从众多业务中找到一个小的业务进行试点，前期的技术方案以满足这个小的业务需求为准，力求先把这个小业务的微服务架构落地实施，从中发现各种问题并予以解决，然后才可以继续考虑更大规模的推广

## 做好技术取舍

- 一切以业务的实际情况为准，只要满足当前的需求就好，切忌好高骛远

## 采用DevOps

- 采用DevOps，对微服务架构进行一站式开发、测试、上线和运维

## 统一微服务治理平台

- 需要开发和运维深入合作，发挥各自专业的特长，将微服务治理的功能以及之前运维系统的基础功能结合在一起，打造成“一站式”微服务治理平台

# 容器化

## 微服务带来的问题

- DevOps可以简单理解为开发和运维的结合，服务的开发者不再只负责服务的代码开发，还要负责服务的测试、上线发布甚至故障处理等全生命周期过程，这样的话就把测试和运维从微服务拆分后所带来的复杂工作中解放出来
- DevOps要求开发、测试和发布的流程必须自动化，这就需要**保证开发人员将自己本地部署测试通过的代码和运行环境，能够复制到测试环境中去，测试通过后再复制到线上环境进行发布**。
- 虽然这个过程看上去好像复制代码一样简单，但在现实时，本地环境、测试环境以及线上环境往往是隔离的，软件配置环境的差异也很大，这也导致了开发、测试和发布流程的割裂

## Docker

> Docker是容器技术的一种，事实上已经成为业界公认的容器标准

- 容器通过Namespace和Cgroups这两种机制，可以拥有自己的root文件系统、自己的网络配置、自己的进程空间，甚至是自己的用户ID空间，这样的话容器里的进程就像是运行在宿主机上的另外一个单独的操作系统内，从而实现与宿主机操作系统里运行的其他进程隔离
- Docker镜像不光可以打包应用程序本身，而且还可以打包应用程序的所有依赖，甚至可以包含整个操作系统

	## 微服务容器化实践

- Docker能帮助解决服务运行环境可迁移问题的关键，就在于Docker镜像的使用上，实际在使用Docker镜像的时候往往并不是把业务代码、依赖的软件环境以及操作系统本身直接都打包成一个镜像，而是利用Docker镜像的**分层机制**，在每一层通过编写Dockerfile文件来逐层打包镜像。这是因为虽然不同的微服务依赖的软件环境不同，但是还是存在大大小小的相同之处，因此在打包Docker镜像的时候，可以分层设计、逐层复用，这样的话可以减少每一层镜像文件的大小。
- 基础环境层。这一层定义操作系统运行的版本、时区、语言、yum源、TERM等。
- 运行时环境层。这一层定义了业务代码的运行时环境，比如Java代码的运行时环境JDK的版本。
- Web容器层。这一层定义了业务代码运行的容器的配置，比如Tomcat容器的JVM参数。
- 业务代码层。这一层定义了实际的业务代码的版本，比如是V4业务还是blossom业务。

# 容器化运维

> 容器化改造对微服务是十分必要的，但Docker也不是“银弹”，同样会产生新的复杂度问题，比如引入Docker后旧的针对物理机的运维模式就无法适应了，需要一种新的针对容器的运维模式

- 业务容器化后，运维面对的不再是一台台实实在在的物理机或者虚拟机了，而是一个个Docker容器，它们可能都没有固定的IP
- 这时候就需要一个面向容器的新型运维平台，它能够在现有的物理机或者虚拟机上创建容器，并且能够像运维物理机或者虚拟机一样，对容器的生命周期进行管理，通常我们叫它“容器运维平台”。一个容器运维平台通常包含以下几个组成部分：镜像仓库、资源调度、容器调度和服务编排

## 镜像仓库

> 镜像仓库的概念其实跟Git代码仓库类似，就是有一个集中存储的地方，把镜像存储在这里，在服务发布的时候，各个服务器都访问这个集中存储来拉取镜像，然后启动容器

### 权限控制

- 必须登录才可以访问
- 对镜像按照项目的方式进行划分

### 镜像同步

- 在实际的生产环境中，往往需要把镜像同时发布到几十台或者上百台集群节点上，单个镜像仓库实例往往受带宽原因限制无法同时满足大量节点的下载需求，这个时候就需要配置多个镜像仓库实例来做负载均衡，同时也就产生镜像在多个镜像仓库实例之间同步的问题了
- 一般来说，有两种方案，一种是一主多从，主从复制的方案，比如开源镜像仓库[Harbor](https://github.com/goharbor/harbor)采用了这种方案；另一种是P2P的方案，比如阿里的容器镜像分发系统[蜻蜓](https://alibaba.github.io/Dragonfly/)采用了P2P方案

### 高可用性

- 多IDC，双主复制策略，互相复制镜像，这样的话即使有一个IDC出现问题，另外一个IDC仍然能够提供服务

## 资源调度

- 服务部署的集群主要包括三种：物理机集群、虚拟机集群、公有云集群
- 资源调度最大的难点不在于机器的创建和容器的部署，而在于如何对接各个不同的集群，统一管理来自不同集群的机器权限管理、成本核算以及环境初始化等操作，这个时候就需要有一个统一的层来完成这个操作

## 容器调度

> 容器调度的问题，说的是现在集群里有一批可用的物理机或者虚拟机，当服务需要发布的时候，该选择哪些机器部署容器的问题

- 基于Docker的容器调度系统有Docker原生的调度系统[Swarm](https://docs.docker.com/engine/swarm/)、Mesosphere出品的[Mesos](http://mesos.apache.org/)，以及Google开源的大名鼎鼎的[Kubernetes](https://kubernetes.io/)

### 主机过滤

- 存活过滤
- 硬件过滤
- 容器层次的过滤，可以实现只有运行了某个容器的主机才会被加入候选集等功能

### 调度策略

- 调度策略主要是为了解决容器创建时选择哪些主机最合适的问题，一般都是通过给主机打分来实现的。比如Swarm就包含了两种类似的策略：spread和binpack，它们都会根据每台主机的可用CPU、内存以及正在运行的容器的数量来给每台主机打分。
- spread策略会选择一个资源使用最少的节点，以使容器尽可能的分布在不同的主机上运行。它的好处是可以使每台主机的负载都比较平均，而且如果有一台主机有故障，受影响的容器也最少。
- binpack策略恰恰相反，它会选择一个资源使用最多的节点，好让容器尽可能的运行在少数机器上，节省资源的同时也避免了主机使用资源的碎片化

## 服务编排

### 服务依赖

- 如果服务A调度的前提必须是先有服务B，这样的话就要求在进行容器调度的时候，还需要考虑服务之间的依赖关系
- Docker官方提供了[Docker Compose](https://github.com/docker/compose)的解决方案。它允许用户通过一个单独的docker-compose.yaml文件来定义一组相互关联的容器组成一个项目，从而以项目的形式来管理应用

### 服务发现

> 容器调度完成以后，容器就可以启动了，但此时容器还不能对外提供服务，服务消费者并不知道这个新的节点，所以必须具备服务发现机制，使得新的容器节点能够加入到线上服务中去

- 基于Nginx的服务发现：主要是针对提供HTTP服务的
- 基于注册中心的服务发现：主要是针对提供RPC服务的

### 自动扩缩容

- 容器完成调度后，仅仅做到有容器不可用时故障自愈还不够，有时候还需要根据实际服务的运行状况，做到自动扩缩容

## 微博容器运维平台DCP

- ![avatar](DCP架构.jpg)

### 基础设施层

- DCP中基础设施层主要用于提供各种基础设施，以保证其他层功能的正常运行。通常来讲，主要包括以下几个基础组件：用于存放容器镜像的镜像仓库、提供监控服务的监控中心、实时监控系统容量以便于自动扩缩容的容量评估系统以及容器创建后，如何加入线上服务的服务发现组件，其中**镜像仓库是DCP最核心的基础组件**

### 主机层

- DCP中主机层的功能主要是为了完成资源的调度，也就是针对不同的集群，完成主机的创建、成本的管理以及配置初始化工作，也叫Pluto层

### 调度层

- DCP中调度层的主要功能是在可用的主机上创建容器

### 编排层

- DCP中编排层的主要作用是对服务进行整合以对外提供服务，主要包括服务依赖、服务发现以及自动扩缩容

# DevOps

## 什么是DevOps

- DevOps是一种新型的业务研发流程，业务的开发人员不仅需要负责业务代码的开发，还需要负责业务的测试以及上线发布等全生命周期，真正做到掌控服务全流程
- 要实现DevOps，就必须开发完成代码开发后，能自动进行测试，测试通过后，能自动发布到线上。对应的这两个过程就是CI和CD，具体来讲就是：
  - CI（Continuous Integration），持续集成。开发完成代码开发后，能自动地进行代码检查、单元测试、打包部署到测试环境，进行集成测试，跑自动化测试用例
  - CD（Continuous Deploy），持续部署。代码测试通过后，能自动部署到类生产环境中进行集成测试，测试通过后再进行小流量的灰度验证，验证通过后代码就达到线上发布的要求了，就可以把代码自动部署到线上

## 实践

- 目前业界比较通用的实现DevOps的方案主要有两种，一种是使用[Jenkins](https://jenkins.io/)，一种是使用[Git](https://gitlab.com/)[L](https://gitlab.com/)[ab](https://gitlab.com/)

1. 持续集成，这个步骤的主要作用是确保每一次代码的Merge Request都测试通过，可随时合并到代码的Develop分支，主要包括四个阶段：build阶段（开发分支代码的编译与单元测试）、package阶段（开发分支代码打包成Docker镜像）、deploy阶段（开发分支代码部署到测试环境）、test阶段（开发分支代码集成测试）。

2. 持续交付，这个步骤的主要作用是确保所有代码合并Merage Request到Develop分支后，Develop分支的代码能够在生产环境中测试通过，并进行小流量灰度验证，可随时交付到线上。主要包括五个阶段：build阶段（Develop分支的代码编译与单元测试）、package阶段（Develop分支的代码打包成Docker镜像）、deploy阶段（Develop分支的代码部署到测试环境）、test阶段（Develop分支的代码集成测试）、canary阶段（Develop分支的代码的小流量灰度验证）。

3. 持续部署，这个步骤的主要作用是合并Develop分支到Master主干，并打包成Docker镜像，可随时发布到线上。主要包括四个阶段：build阶段（Master主干的代码编译与单元测试）、package阶段（Master主干的代码打包成Docker镜像）、clear阶段（Master主干的代码Merge回Develop分支）、production阶段（Master主干的代码发布到线上）。

## 关键点

- 持续集成阶段
  - 代码检查
  - 单元测试：单元测试是针对每个具体代码模块的，单元测试的覆盖度越高，各个代码模块出错的概率就越小
  - 集成测试：集成测试就是将各个代码的修改集成到一起，统一部署在测试环境中进行测试。为了实现整个流程的自动化，集成自测阶段主要的任务就是跑每个服务的自动化测试用例
- 持续交付阶段
  - 持续交付阶段的主要目的是保证最新的业务代码，能够在类生产环境中可能够正常运行，一般做法都是从线上生成环境中摘掉两个节点，然后在这两个节点上部署最新的业务代码，再进行集成测试，集成测试通过后再引入线上流量，来观察服务是否正常

- 持续部署阶段
  - 持续部署阶段的主要目的把在类生产环境下运行通过的代码自动的发布到线上所有节点中去，这里的关键点就在于实际的线上发布阶段并不是想象中的那么直接。
  - 这个阶段，持续部署一般并不要求那么完美，许多公司在这个阶段都采用了手动发布的方式以控制风险，或者只做到持续交付阶段，对于持续部署并不要求自动化

# 容量规划

> 容量规划系统的作用是**根据各个微服务部署集群的最大容量和线上实际运行的负荷，来决定各个微服务是否需要弹性扩缩容，以及需要扩缩容多少台机器**

## 容量评估

- 选择合适的压测指标
  - 系统类指标，比如机器的CPU使用率、内存占用量、磁盘I/O使用率以及网卡带宽等
  - 服务类指标，比如接口响应的平均耗时、P999耗时、错误率
  - 在压测时，除了观察以上这些指标以外，还可以观察接口的慢速比，也就是接口响应时间高于某个阈值的比例
- 压测获取单机的最大容量
  - 单机压测一般有两种方式，一种是通过日志回放等手段，模拟线上流量来对单机进行压测；一种是通过TCP-Copy的方式，把线上机器的流量拷贝过来对单机进行压测
  - 集群压测是对整个集群进行压测，以获取单机的最大容量。一般做法是通过不断把线上集群的节点摘除，以减少机器数的方式，来增加线上节点单机的流量，从而达到压测的目的
- 实时获取集群的运行负荷
  - 通过压测能够获取到单机的最大容量，再乘以集群内的机器数量就是集群的最大容量了，下一步获取集群实际运行的负荷，就可以判断集群是否需要扩容了

## 调度决策

- 划分了两条线，一条是安全线，一条是致命线。当集群的水位线位于致命线以下时，就需要立即扩容，在扩容一定数量的机器后，水位线回到安全线以上并保持一段时间后，就可以进行缩容了
- 扩容：在决定扩多少机器时，一般有两种方式，一种是按数量，一种是按比例。因为不同的集群内机器数量差别可能很大，所以一般采取按比例的方式，举个例子比如每一次扩容都增加30%的机器数量，再看扩容后的水位线是否处于致命线以上了。
- 缩容：在扩容完成后，集群的水位线保持在安全线以上一段时间后，就需要缩容，以节省机器成本。可以根据实际业务特点来决定多久后可以缩容

# 多机房部署实践

## 多机房负载均衡

- 当服务部署在多个机房时，最简单的就是遵循用户就近访问的原则
- 在实际部署时，有时候并不能完全遵循就近访问的原则，而是要**根据需要调配流量，达到各个机房流量均衡的目的**。在实践中可以通过两种方法来切换流量：一种是在DNS解析时，把一部分北方用户的请求解析到电信机房的VIP或者把一部分南方用户的请求解析到联通机房的VIP；另一种是在Nginx转发请求时，把一部分电信机房的Tomcat容器配置到联通机房的Nginx的upstream里或者把一部分联通机房的Tomcat容器配置到电信机房的Nginx的upstream里

## 多机房数据同步

> 要保证多个机房的数据一致，不仅要保证数据库层的数据一致，还需要保证缓存层的数据一致

### 主从机房架构

- 把所有的写请求都发给主机房，由主机房来负责写所有机房的缓存和本机房的数据库，而其他机房的数据库则通过MySQL的binlog同步机制实现数据同步

### 独立机房架构

- 机房都有写请求，并通过一个叫WMB的消息同步组件把各自机房的写请求同步一份给对方机房，这样的话相当于每个机房都有全量的写请求。
- 每个机房的处理机接收到写请求后更新各自机房的缓存，只有一个机房会更新数据库，其他机房的数据库通过MySQL的binlog同步机制实现数据同步

### WMB的消息同步功能

- WMB消息同步组件的功能就是把一个机房的写请求发给另外一个机房
  - reship，负责把本机房的写请求分发一份给别的机房。
  - collector，负责从别的机房读取写请求，然后再把请求转发给本机房的处理机。

- MCQ消息队列实现
- RPC调用实现

## 多机房数据一致性

- 非金融业务服务主要是通过**消息对账机制**来保证最终一致性
- 系统会给每一次写请求生成一个全局唯一的requestId，联通机房的写请求一方面会调用联通机房的处理机RPC来修改缓存和数据库，另一方面还会调用联通机房的reship RPC，reship RPC再调用电信机房的collector RPC来同步写请求，电信机房的collector RPC最后会调用电信机房的处理RPC来更新缓存。在这整个过程的每一个环节，requestId始终保持向下传递，无论是处理成功或者失败都记录一条包含requestId和机房标记的处理日志，并写到Elasticsearch集群上去。然后通过一个定时线程，每隔1分钟去扫描Elasticsearch集群上的日志，找出包含同一个requestId的不同机房的处理日志，然后验证是否在各个机房请求都处理成功了，如果有的机房某一阶段处理失败，则可以根据日志信息重试该阶段直到成功，从而保证数据的最终一致性。

# 混合云部署实践

## 跨云服务的负载均衡

## 跨云服务的数据同步

- 私有云与公有云之间的网络隔离：一般来讲，出于安全的需要，企业内部机房同公有云机房之间的网络是隔离的，为了实现互通，需要架设专门的VPN网络或者专线。
- 数据库能否上云：公有云厂商普遍采用了虚拟化技术，不同公司的虚拟机有可能部署在同一台物理机上，所以能否实现有效的数据隔离非常关键，尤其对于企业的核心业务数据，往往会出于安全隐私的考虑，并不敢直接放到云上部署。一般只部署了缓存，当缓存穿透时需要访问内网数据库

## 跨云服务的容器运维

### 跨云的主机管理

- 主机-服务池-集群

### 跨云服务发现

- 云上部署的服务还可以直接使用SLB来做服务发现

### 跨云弹性扩容

- 当有流量上涨，超出了内部私有云机房部署所能承受的范围时，可以扩容阿里云机房的机器，然后把流量切换到阿里云机房。切流量也有两种方案：一是在DNS层切换，把原先解析到私有云机房VIP的流量，解析到阿里云机房的SLB，这时候阿里云机房部署的SLB、Nginx和Java Web都需要扩容；一种是在Nginx层切换，把原先转发到私有云机房Nginx的流量，转发到阿里云机房的Java Web，这个时候只需要扩容阿里云的Java Web。

### 跨云服务编排

- 在进行服务编排时，如果服务跨云部署，就要考虑跨机房访问的问题了，对应机房的服务都要做扩容

# Service Mesh

> Service Mesh是一种新型的用于处理服务与服务之间通信的技术，尤其适用以云原生应用形式部署的服务，能够保证服务与服务之间调用的可靠性。在实际部署时，Service Mesh通常以轻量级的网络代理的方式跟应用的代码部署在一起，从而以应用无感知的方式实现服务治理

- 出现的原因
  - 跨语言服务调用的需要
  - 云原生应用服务治理的需要

## Service Mesh的实现原理

### SideCar

- 在传统的微服务架构下服务消费者这边除了自身的业务逻辑实现外，还需要集成部分服务框架的逻辑，比如服务发现、负载均衡、熔断降级、封装调用等，而服务提供者这边除了实现服务的业务逻辑外，也要集成部分服务框架的逻辑，比如线程池、限流降级、服务注册等

- 在Service Mesh架构中，服务框架的功能都集中实现在SideCar里，并在每一个服务消费者和服务提供者的本地都部署一个SideCar，服务消费者和服务提供者只管自己的业务实现，服务消费者向本地的SideCar发起请求，本地的SideCar根据请求的路径向注册中心查询，得到服务提供者的可用节点列表后，再根据负载均衡策略选择一个服务提供者节点，并向这个节点上的SideCar转发请求，服务提供者节点上的SideCar完成流量统计、限流等功能后，再把请求转发给本地部署的服务提供者进程，从而完成一次服务请求
- 边车模式又叫做跨斗模式，又可以叫做搭档模式。比较常见的是，对应生活中三轮摩托车，通过对一个两轮摩托车，**加上一个挎斗，来拓展现有的能力**。使其不改变原来的功能，而增加新的服务。
- 我们可以把服务消费者节点上的SideCar叫作正向代理，服务提供者节点上的SideCar叫作反向代理，那么Service Mesh架构的关键点就在于服务消费者发出的请求如何通过正向代理转发以及服务提供者收到的请求如何通过反向代理转发
  - 基于iptables的网络拦截
  - 采用协议转换的方式

### Control Plane

- 所有的SideCar就组成了一个服务网格，再通过一个统一的地方与各个SideCar交互，就能控制网格中流量的运转了，这个统一的地方就在Sevice Mesh中就被称为Control Plane
- 服务发现。服务提供者会通过SideCar注册到Control Plane的注册中心，这样的话服务消费者把请求发送给SideCar后，SideCar就会查询Control Plane的注册中心来获取服务提供者节点列表。
- 负载均衡。SideCar从Control Plane获取到服务提供者节点列表信息后，就需要按照一定的负载均衡算法从可用的节点列表中选取一个节点发起调用，可以通过Control Plane动态修改SideCar中的负载均衡配置。
- 请求路由。SideCar从Control Plane获取的服务提供者节点列表，也可以通过Control Plane来动态改变，比如需要进行A/B测试、灰度发布或者流量切换时，就可以动态地改变请求路由。
- 故障处理。服务之间的调用如果出现故障，就需要加以控制，通常的手段有超时重试、熔断等，这些都可以在SideCar转发请求时，通过Control Plane动态配置。
- 安全认证。可以通过Control Plane控制一个服务可以被谁访问，以及访问哪些信息。
- 监控上报。所有SideCar转发的请求信息，都会发送到Control Plane，再由Control Plane发送给监控系统，比如Prometheus等。
- 日志记录。所有SideCar转发的日志信息，也会发送到Control Plane，再由Control Plane发送给日志系统，比如Stackdriver等。
- 配额控制。可以在Control Plane里给服务的每个调用方配置最大调用次数，在SideCar转发请求给某个服务时，会审计调用是否超出服务对应的次数限制。

# Istio

> Linkerd可以说是第一代Service Mesh产品，到了今天当我们再谈到Service Mesh时，往往第一个想到的是[Istio](https://istio.io/)

- ![avatar](Istio架构.jpg)

## Proxy

- Istio的Proxy采用的是Envoy，Envoy跟Linkerd是同一代的产品，既要作为服务消费者端的正向代理，又要作为服务提供者端的反向代理
  - 性能损耗低
  - 可扩展性高
  - 动态可配置

## Pilot

- Pilot的作用是实现流量控制，它通过向Envoy下发各种指令来实现流量控制

- Rules API，对外封装统一的API，供服务的开发者或者运维人员调用，可以用于流量控制。
- Envoy API，对内封装统一的API，供Envoy调用以获取注册信息、流量控制信息等。
- 抽象模型层，对服务的注册信息、流量控制规则等进行抽象，使其描述与平台无关。
- 平台适配层，用于适配各个平台如Kubernetes、Mesos、Cloud Foundry等，把平台特定的注册信息、资源信息等转换成抽象模型层定义的平台无关的描述。

### 服务发现和负载均衡

- 服务提供者注册到对应平台的注册中心中去，比如Kubernetes集群中的Pod，启动时会注册到注册中心etcd中。然后服务消费者在调用服务时，请求会被Proxy拦截，然后Proxy会调用Pilot查询可用的服务提供者节点，再以某种负载均衡算法选择一个节点发起调用

### 请求路由

- 可以通过调用Pilot提供的Rules API，Pilot就会向Proxy下发路由规则，Proxy在转发请求时就按照给定的路由规则请求

### 超时重试

- 缺省状态下，Proxy转发HTTP请求时的超时是15s，可以通过调用Pilot提供的Rules API来修改路由规则，覆盖这个限制

### 故障注入

- 在不杀死服务节点的情况下，通过修改路由规则，将特定的故障注入到网络中。它的原理是在TCP层制造数据包的延迟或者损坏，从而模拟服务超时和调用失败的场景，以此来观察应用是否健壮

## Mixer

- Mixer的作用是实现策略控制和监控日志收集等功能，实现方式是每一次Proxy转发的请求都要调用Mixer
- 理论上每一次的服务调用Proxy都需要调用Mixer，一方面检查调用的合法性，一方面要上报服务的监控信息和日志信息，所以这就要求Mixer必须是高可用和低延迟的
  - Proxy端的本地缓存。为了减少Proxy对Mixer的调用以尽量降低服务调用的延迟，在Proxy这一端会有一层本地缓存，但由于Proxy作为SideCar与每个服务实例部署在同一个节点上，所以不能对服务节点有太多的内存消耗，所以就限制了Proxy本地缓存的大小和命中率。
  - Mixer的本地缓存。Mixer是独立运行的，所以可以在Mixer这一层使用大容量的本地缓存，从而减少对后端基础设施的调用，一方面可以减少延迟，另一方面也可以最大限度减少后端基础设施故障给服务调用带来的影响。

- 策略控制：Istio支持两类的策略控制，一类是对服务的调用进行速率限制，一类是对服务的调用进行访问控制，它们都是通过在Mixer中配置规则来实现的。具体来讲，速率限制需要配置速率控制的yaml文件，每一次Proxy转发请求前都会先调用Mixer，Mixer就会根据这个yaml文件中的配置，来对调用进行速率限制。访问控制需要配置访问控制的yaml文件，每一次Proxy转发请求前都会先调用Mixer，Mixer就会根据这个yaml文件中的配置，来对调用进行访问控制
- 监控和日志收集：跟策略控制的实现原理类似，Mixer的监控、日志收集功能也是通过配置监控yaml文件来实现的，Proxy发起的每一次服务调用都会先调用Mixer，把监控信息发给Mixer，Mixer再根据配置的yaml文件来决定监控信息该发到哪

## Citadel

- Citadel的作用是保证服务之间访问的安全，实际的安全保障并不是Citadel独立完成的，而是需要Proxy、Pilot以及Mixer的配合

- Citadel里存储了密钥和证书。
- 通过Pilot把授权策略和安全命名信息分发给Proxy。
- Proxy与Proxy之间的调用使用双向TLS认证来保证服务调用的安全。
- 最后由Mixer来管理授权和审计。

# 微博ServiceMesh实践之路

## 跨语言服务调用的需求

- 中间链路损耗大
- 全链路扩容难
- 混合云部署难

## Yar协议

- Motan协议与Yar协议在基本数据结构和序列化方式的支持有所不同，需要经过复杂的协议转换
- 服务调用还必须依赖Nginx，所以调用链路多了一层，在应用部署和扩容时都要考虑Nginx

## gRPC

- gRPC协议高度依赖PB序列化，而PHP对PB的兼容性不是很好

## 代理

- 通过一个Agent也就是代理，来帮助PHP进程来完成服务框架的各种功能，PHP进程本身只需要负责运行业务逻辑的代码，以及最简单的Motan协议解析

## Service Mesh

- 不仅客户端的调用需要经过本地的Agent处理后再转发给服务端，服务端在处理前也需要经过本地的Agent，最后再由服务端业务逻辑处理